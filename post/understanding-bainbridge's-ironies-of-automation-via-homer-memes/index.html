<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    
    <meta itemprop="name" content="Understanding Bainbridge&#39;s Ironies of Automation via Homer memes | YTMNB.com">
    <meta itemprop="description" content="Lisanne Bainbridge meet Homer J. Simpson">

    
    <meta name="twitter:title" content="Understanding Bainbridge&#39;s Ironies of Automation via Homer memes | YTMNB.com">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:description" content="Lisanne Bainbridge meet Homer J. Simpson">
    <meta name="twitter:site" content="@seereadnow">
    <meta name="twitter:creator" content="@seereadnow">
    <meta name="twitter:image:src" content="https://www.ytmnb.com/twitter.jpg">

    
    <meta name="og:title" content="Understanding Bainbridge&#39;s Ironies of Automation via Homer memes | YTMNB.com">
    <meta name="og:description" content="Lisanne Bainbridge meet Homer J. Simpson">
    <meta name="og:image" content="https://www.ytmnb.com/og.jpg">
    <meta name="og:url" content="https://www.ytmnb.com/">
    <meta name="og:site_name" content="YTMNB.com">
    <meta name="og:locale" content="en_GB">
    <meta name="og:type" content="website">

    <link rel="icon" type="image/x-icon" href="/favicon.ico">

    <title>Understanding Bainbridge&#39;s Ironies of Automation via Homer memes | YTMNB.com</title>

    <link rel="stylesheet" href="/assets/main.bundle.css">

    
  </head>
  <body class="flex flex-col min-h-screen">
    <!-- <p class="top-notice"> </p> -->

    <header>
  <nav class="container mx-auto max-w-3xl p-6 border-b-2 border-red-500">
    <div>
      <h1>
        <a href="/">YTMNB.com</a>
      </h1>
      <p>“You’re the man now! blog - tech realism, full stack development, asides</p>
    </div>

    <!--
    <ul class="flex flex-wrap sm:w-32 w-full mt-6 md:justify-between justify-evenly">
      <li>
        <a href="/404.html">404</a>
      </li>
    </ul>
    -->
  </nav>
</header>

    <main class="container mx-auto max-w-3xl p-6">
      
    <div>
        <div class="py-6">
            
                
                    <p class=" text-sm ">
                        <span datetime="Fri Feb 18 2022 18:00:00 GMT-0600 (Central Standard Time)">2022.02.19</span></p>
                
            

            <h2 class="text-3xl"><a href="">Understanding Bainbridge's Ironies of Automation via Homer memes</a></h2>

            
                <p class="excerpt">Lisanne Bainbridge meet Homer J. Simpson</p>
            

            
                <p class="">
                    <a class="tag tech-realism" href="/tag/tech-realism">tech-realism</a> 
                </p>
            

            
                <h3 class="pt-2 uppercase text-sm">Contents</h3>
                <nav class="toc">
                <ol>
                    
                    <li><a href="#automation-necessitates-monitoring%E2%80%A6">Automation necessitates monitoring…</a>
            		</li>

                    <li><a href="#%E2%80%A6encourages-deskilling">…encourages deskilling</a>
            		</li>

                    <li><a href="#%E2%80%A6but-requires-skilled-intervention">…but requires skilled intervention</a>
            		</li>

                    <li><a href="#%E2%80%A6while-enabling-poor-supervision">…while enabling poor supervision</a>
            		</li>

                    <li><a href="#%E2%80%A6and-demoralizing-an-overly-liable-operator.">…and demoralizing an overly liable operator.</a>
            		</li>

                    <li><a href="#alarms-only-help-so-much%E2%80%A6">Alarms only help so much…</a>
            		</li>

                    <li><a href="#%E2%80%A6because-automation-encourages-routine.">…because automation encourages routine.</a>
            		</li>

                    <li><a href="#modal-interfaces-can-confuse%E2%80%A6">Modal interfaces can confuse…</a>
            		</li>

                    <li><a href="#%E2%80%A6and-encourage-poor-comprehension.">…and encourage poor comprehension.</a>
            		</li>

                    <li><a href="#repair-can-require-improvisation%E2%80%A6">Repair can require improvisation…</a>
            		</li>

                    <li><a href="#%E2%80%A6and-simulation-can-only-help-so-much.">…and simulation can only help so much.</a>
            		</li>

                    <li><a href="#tldr%3A-automation-adds-complexity-and-that-means-more-challenging-decisions.">tldr: Automation adds complexity and that means more challenging decisions.</a>
            		</li>
                </ol>
            </nav>
            
        </div>

        <div class="content post border-y-2 border-red-500 py-6">

            <p>Ask any experienced dev and they will tell you: in attempting to solve almost any problem with software, we are liable to create others.</p>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3o6Mbmx4k4D0xwSRDa" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<p>To better understand this dynamic, I read (ok, skimmed) Robert Hoffman and Laura Militello’s lengthy <a href="https://www.amazon.com/Perspectives-Cognitive-Task-Analysis-Applications/dp/0805861408">Perspectives on Cognitive Task Analysis</a>, an acronym-heavy technical survey peppered with vignettes of industrial snafus and over cluttered fighter pilot displays.</p>
<p>In it, I found an excellent summary of Lisanne Bainbridge’s often cited <a href="https://ckrybus.com/static/papers/Bainbridge_1983_Automatica.pdf">Ironies of Automation</a> paper from 1983.</p>
<p>And given that an analysis of nuclear plant procedure preceded this section, I decided to illustrate these ironies with GIFs of America’s favorite nuclear plant operator – Homer J. Simpson.</p>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/xT5LMuLetv1pYsqH0A" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<p>So without further ado, the ironies of automation.</p>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/l2JdULh6nrvHF1hug" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="automation-necessitates-monitoring%E2%80%A6" tabindex="-1">Automation necessitates monitoring…</h3>
<blockquote>
<p>One consequence of automation is that the human is actually given a nearly impossible task. If a process can be specified and a computer can make complex decisions more quickly and effectively than a human, the operator must determine when the automation is working properly.</p>
<blockquote>
<p>The monitor needs to know what the correct behavior of the process should be. … Such knowledge requires special training or special displays … [there may be] no way in which the human operator can check in real-time that the computer is following its rules correctly.</p>
</blockquote>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/xT5LMrX45sQcjqNmVy" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="%E2%80%A6encourages-deskilling" tabindex="-1">…encourages deskilling</h3>
<blockquote>
<p>A second consequence is that skills deteriorate when they are not used. As we know from studies of vigilance, “an operator will not monitor the automatics effectively if they have been operating acceptably for a long period.” The operator has less opportunity to explore and understand how the process is working.</p>
<blockquote>
<p>An operator will only be able to generate successful new strategies for unusual situations if he has an adequate knowledge of the process … the operator has in his head not raw data about the process state but the results of making predictions and decisions about the process which will be useful in future situations.</p>
</blockquote>
<p>This develops only through practice with feedback, and the monitoring role often precludes that.</p>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3o6Mbg5OZ2iqfePCTK" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="%E2%80%A6but-requires-skilled-intervention" tabindex="-1">…but requires skilled intervention</h3>
<blockquote>
<p>A third consequence involves what happens when an automated process goes awry.</p>
<blockquote>
<p>If the human is not involved in on-line control he will not have a detailed knowledge of the current state of the system. … When manual take-over is needed there is likely to be something wrong with the process so that unusual actions will be needed to control it, and one can argue that the operator needs to be more rather than less skilled. … By taking away the easy parts of his task, automation can make the more difficult parts of the human operator’s task more difficult.</p>
</blockquote>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:75%;position:relative;"><iframe src="https://giphy.com/embed/3o6MbgDyQ1AMxXOiYM" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="%E2%80%A6while-enabling-poor-supervision" tabindex="-1">…while enabling poor supervision</h3>
<blockquote>
<p>Monitoring is often predicated on the notion that the operator can call in specialized expertise in unusual situations. Here too is an irony: “The supervisor too will not be able to take over if he has not been reviewing his relevant knowledge or practicing a crucial skill.”</p>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:77%;position:relative;"><iframe src="https://giphy.com/embed/3orif5FaudYtfbVBpm" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="%E2%80%A6and-demoralizing-an-overly-liable-operator." tabindex="-1">…and demoralizing an overly liable operator.</h3>
<blockquote>
<p>In sum, the monitor has a job that is at once very boring and very responsible, “yet there is no opportunity to acquire or maintain the qualities required to handle the responsibility … [when] the job is ‘de-skilled’ by being reduced to monitoring.”   Bainbridge cited studies showing that job satisfaction is higher and stress lower when workers are actively engaged in the control of processes that are complex yet highly controllable.</p>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/l2Je367ozZKoka5RC" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="alarms-only-help-so-much%E2%80%A6" tabindex="-1">Alarms only help so much…</h3>
<blockquote>
<p>Potential solutions to these conundrums have themselves resulted in ironies of automation. One approach is to create alarms and specialized displays for use in certain kinds of unusual situations. Catastrophic problems can be easy to detect.</p>
<p>However, the trends that show a path to failure are not always obvious; displays that are ideal for normal situations may disguise abnormal ones.</p>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3orieRSPKRODbLKBPO" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="%E2%80%A6because-automation-encourages-routine." tabindex="-1">…because automation encourages routine.</h3>
<blockquote>
<p>Furthermore, the automated systems work constantly to correct deviations from the norm, and thus when an alarm sounds or a catastrophic break has occurred, the trend may be beyond the capacity of the human monitor to understand and act on quickly, compounded by the fact that the operator will be most practiced in using the displays that are for routine operations and routine monitoring activities. And if the human operator does not believe or agree with the computer, he may be unable to trace back what it was that the computer did.</p>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3o6MbqRUt6XH1OaGL6" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="modal-interfaces-can-confuse%E2%80%A6" tabindex="-1">Modal interfaces can confuse…</h3>
<blockquote>
<p>Another approach is to create displays that are designed to match the operator’s level of skill […] or proficiency level (e.g., trainee versus journeyman versus expert). In theory, the computer could detect the level of skill or strategic style of the operator and adjust the display accordingly. Bainbridge argued that such capabilities of multiple displays might confuse rather than help:</p>
<blockquote>
<p>The changes between knowledge-based thinking and “reflex” reaction is not solely a function of practice, but also depends on the uncertainty of the environment, so that the same task elements may be done using different types of skill at different times. … We do not know how confused operators would be by display changes which were not under their own control … although operators evidently do think at different levels of complexity and abstraction at different times, it is not clear that they would be able to use, or choose, many different displays under time stress.</p>
</blockquote>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3o6Mbsras7qdAwgABW" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="%E2%80%A6and-encourage-poor-comprehension." tabindex="-1">…and encourage poor comprehension.</h3>
<blockquote>
<p>Another irony that stems from the creation of better interfaces links back to the issue of the degradation of knowledge:</p>
<blockquote>
<p>The more processing for meaning that some data has received, the more effectively it is remembered. This makes one wonder how much the operator will learn about the structure of the process if information about it is presented so successfully that he does not have to think about it to take it in. It certainly would be ironic if we find that the most compatible display is not the best display to give the operator after all! A highly compatible display [that] supports rapid reactions [may not support] acquisition of the knowledge and thinking skills needed in abnormal conditions.</p>
</blockquote>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3o6MbdrSF5Z3Fn97Yk" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="repair-can-require-improvisation%E2%80%A6" tabindex="-1">Repair can require improvisation…</h3>
<blockquote>
<p>There are also ironies that are resultant from training.</p>
<blockquote>
<p>It is inadequate to expect the operator to react to unfamiliar events solely by consulting operating procedures. These cannot cover all the possibilities, so the operator is expected to monitor them and fill in the gaps. However, it is ironic to train operators in following instructions and then put them in the system to provide intelligence.”</p>
</blockquote>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/d2VNBUe0BhUGYqpa" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="%E2%80%A6and-simulation-can-only-help-so-much." tabindex="-1">…and simulation can only help so much.</h3>
<blockquote>
<p>High-fidelity simulations can help workers maintain skills and can provide opportunities to practice some nonroutine situations, but they cannot help in dealing with unknown faults and complex failures having multiple causes that cannot be anticipated (and hence cannot be simulated). A final irony is that “the most successful automated systems, with rare need for manual intervention … may need the greatest investment in human operator training.”</p>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:75%;position:relative;"><iframe src="https://giphy.com/embed/qqtvGYCjDNwac" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<h3 id="tldr%3A-automation-adds-complexity-and-that-means-more-challenging-decisions." tabindex="-1">tldr: Automation adds complexity and that means more challenging decisions.</h3>
<blockquote>
<p>Thus, for a number of reasons it is necessary for the human to be able to understand and follow the operations of the automation. This is, of course, an irony that the automated system was created to help the human cope with the complexity of process being controlled but ends up forcing the human to understand the complexities of the automated system. This can make human performance worse in a number of ways. For instance, when the operator does not understand or trust the automation, he will attempt to make control decisions anyway, and so the additional task of having to monitor the automation adds to workload—ironic, because automation is intended to reduce workload.</p>
</blockquote>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3orifh21okr0EZbICA" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<blockquote>
<p>Bainbridge cited instances in which automation does help, for instance, aircraft autopilots that work to free the pilot from online control and thus allow the pilot to think about the challenges or abnormalities. In such cases, the human knows which process the computer is thinking about and (to some degree) what the computer is trying to accomplish. Good interfaces are ones in which key types of information are presented in dedicated displays (e.g., one display of process plant layout and another of process functionality). “Operators should not have to page between displays to obtain information about abnormal states in parts of the process other than the one they are currently thinking about, nor between displays giving information needed within a single decision process.”</p>
</blockquote>
<p>Does your automation encourage better decisions – or worse?</p>
<!--
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3orifd2IjZjWVkpC4o" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/3o6MbiZ0jySdVDY4pO" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/l2JeblbdfRL0i2qOI" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>
-->
<div class="my-7" style="width:100%;height:0;padding-bottom:76%;position:relative;"><iframe src="https://giphy.com/embed/l2Je4nuc11cMXpzt6" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen=""></iframe></div>
<p>For a more patient read, consider Adrian Colyer’s <a href="https://blog.acolyer.org/2020/01/08/ironies-of-automation/">take</a>.</p>

        </div>
            <p class="uppercase text-xs mt-6">Next</p>
            <p class="mb-2">
                <a href="/post/how-to-livestream-a-presentation-with-screen-sharing-and-audio-sharing/">How to livestream a presentation with screen sharing and audio sharing</a>
            </p>
        
            <p class="uppercase text-xs mt-6">Previous</p>

            <p class="">
                <a href="/post/grappling-with-complexity/">Grappling with Complexity</a>
            </p>
        
    </div>

    </main>
    <footer class="pb-10">
  <p class="block text-center text-sm mb-6">
    <a href="/">YTMNB.com</a>
    <br><br>
    <a target="_blank" href="https://github.com/seereadcode">
      github: @seereadcode
    </a>
    <br>
    <a target="_blank" href="https://twitter.com/seereadnow">
      twitter: @seereadnow
    </a>
  </p>

</footer>

    <!-- <div id="privacy-notice" style="height: 5em" class="sticky bottom-0 py-5 px-2 bg-gray-800 w-full flex justify-center">
    <p class="px-2 text-sm self-center">By using this site, you agree that you have read and understand its <a href="/privacy-policy">Privacy Policy</a>.</p>
    <button aria-label="dismiss" style="height: 32px; width: 32px" class="flex justify-center align-center" id="privacy-notice-button-container">
        <svg id="privacy-notice-button" xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 18 18"><path d="M14.53 4.53l-1.06-1.06L9 7.94 4.53 3.47 3.47 4.53 7.94 9l-4.47 4.47 1.06 1.06L9 10.06l4.47 4.47 1.06-1.06L10.06 9z"/></svg> 
    </button>
</div>
-->

    <script src="https://unpkg.com/clipboard@2/dist/clipboard.min.js"></script>
    <script src="/assets/main.bundle.js"></script>
  </body>
</html>
